{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Machine Learning (ML)\n",
    "### 2 Main Types\n",
    "1. Supervised learning: labeled data (e.g. there is a special attribute called the \"class\", that we are interested in predicting for \"unseen\" instances)\n",
    "    * If the class is numeric -> regression task\n",
    "    * If the class is categorical -> classification task\n",
    "    * Example algorithm: `kNN` (k nearest neighbors)\n",
    "2. Unsupervised learning: unlabeled data (e.g. no class attribute)\n",
    "    * Example algorithm: k means clustering\n",
    "\n",
    "### Supervised learning\n",
    "* We need a way to divide a dataset into a training set and a testing set\n",
    "    * Train/build an algorithm/model using a training set\n",
    "    * Test/evaluate an algorithm/model using the testing set\n",
    "        * Testing has \"unseen instances\"\n",
    "    * Note: Training and testing set are *different*\n",
    "* Example: tiny t-shirt dataset\n",
    "    * Goal: predict t-shirt sizes using height and weight of people\n",
    "    * Training set\n",
    "        * 4 instances, 2 attributes (AKA features), 1 class (t-shirt size)\n",
    "    * Testing set\n",
    "        * 1 unseen instance (161cm, 63kg)\n",
    "        * What should the t-shirt size be?\n",
    "        * Let say the \"actual\" AKA \"ground truth value\" for this instance is M (Medium)\n",
    "        * If `kNN` predicts M, then we have 100% accuracy\n",
    "        * If `kNN` predicts L, then we have 0% accuracy\n",
    "\n",
    "### `kNN` Algorithm\n",
    "* Identify the k nearest neighbor in the training set for the unseen instance\n",
    "    * The most frequent class label amongst these k neighbors will be the algorithm's prediction for the class label for the unseen instance\n",
    "* We need a way to measure \"nearness\" or \"closeness\"\n",
    "    * 2-dimensional: pythagorean theorem\n",
    "    * N-dimensional: euclidean distance $dist(a, b) = \\sqrt{\\sum_{i=1}^{n} (a_i - b_i)^2}$\n",
    "* To avoid an inadvertent weighting of our attributes when we use this formual, we typically apply a preprocessing step called nomralization (or standardization)\n",
    "    * For `kNN`, we will use a normalization technique called min-max scaling\n",
    "    * For each attribute, subtract the min and divide by the range\n",
    "    * Each attrbute will be in `[0, 1]`\n",
    "* Trace time!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>t-shirt size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165</td>\n",
       "      <td>61</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168</td>\n",
       "      <td>66</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   height(cm)  weight(kg) t-shirt size\n",
       "0         158          58            M\n",
       "1         163          61            M\n",
       "2         165          61            L\n",
       "3         168          66            L"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"shirt_sizes.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   height(cm)  weight(kg)\n",
      "0         158          58\n",
      "1         163          61\n",
      "2         165          61\n",
      "3         168          66\n",
      "0    M\n",
      "1    M\n",
      "2    L\n",
      "3    L\n",
      "Name: t-shirt size, dtype: object\n",
      "[[161, 63]]\n"
     ]
    }
   ],
   "source": [
    "# We will use the sci-kit learn ML library\n",
    "# However, they are mostly shallow ML library\n",
    "# Notation:\n",
    "# X: a feature matrix (2D; rows are feature vectors aka instances)\n",
    "# remove the class and store in y\n",
    "# y: a class vector (1D; what you are trying to predict)\n",
    "# X and y are parallel\n",
    "# Add a_train or _test to denote training or testing set\n",
    "X_train = df.drop(\"t-shirt size\", axis=1)\n",
    "print(X_train)\n",
    "y_train = df[\"t-shirt size\"]\n",
    "print(y_train)\n",
    "\n",
    "X_test = [[161, 63]] #2D, add more if there is more testing set\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.   ]\n",
      " [0.5   0.375]\n",
      " [0.7   0.375]\n",
      " [1.    1.   ]]\n",
      "[[0.3   0.625]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tony/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_normalized = scaler.transform(X_train)\n",
    "print(X_train_normalized)\n",
    "\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "print(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M']\n",
      "(array([[0.32015621, 0.47169906, 0.69327123]]), array([[1, 2, 0]]))\n"
     ]
    }
   ],
   "source": [
    "# get prediction\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3, metric=\"euclidean\")\n",
    "knn_clf.fit(X_train_normalized, y_train) # to train\n",
    "y_predicted = knn_clf.predict(X_test_normalized) # to test\n",
    "print(y_predicted)\n",
    "print(knn_clf.kneighbors(X_test_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing Thoughts on `kNN`\n",
    "* Not a very efficient algorithm\n",
    "* What if our attributes are not numeric (they are categorical?)\n",
    "    * Convert category labels to integers\n",
    "        * `from sklearn.preprocessing import Label Encoder`\n",
    "    * Use a different distance metric (or make your own)\n",
    "* Note that `kNN` is not the only supervised ML algorithm (it is a good one to start learning with though)\n",
    "    * Naive Bayes\n",
    "    * Decision trees\n",
    "    * Random forests\n",
    "    * Support vector machines (SVMs)\n",
    "    * Neural networks\n",
    "    * etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm-up Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 2) (18,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"shirt_sizes_long.csv\")\n",
    "\n",
    "X = df.drop(\"t-shirt size\", axis=1)\n",
    "X = scaler.fit_transform(X)\n",
    "y = df[\"t-shirt size\"]\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Evaluation\n",
    "* In our previous demo, we had one instance in our \"test\" set\n",
    "    * If our classifier correctly predicts the label for this instacne -> 100% accuracy\n",
    "    * If our classifier incorrectly predicts the label for this instacne -> 0% accuracy\n",
    "* Notes:\n",
    "    * We want a \"large\" testing set so we can get a good big picture of how well our classifier has learned\n",
    "    * Accuracy doesn't tell the whole story \n",
    "* We need a way to \"divide\" our dataset into training and testing\n",
    "    * A few way to do this:\n",
    "        1. Holdout method\n",
    "        1. Cross validation\n",
    "\n",
    "### Holdout Method\n",
    "* \"Hold out\" a certain number or percentage of instances for testing\n",
    "    * Train on the remaining instances\n",
    "* Typically use a common \"split\" for how much to hold out\n",
    "    * 2:1 -> 1/3 held for testing, 2/3 held for training\n",
    "    * 25% held out for testing, 75% held out for training\n",
    "        * Default for sci-kit learn's `train_test_split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58333333 0.3       ]\n",
      " [1.         1.        ]\n",
      " [0.83333333 0.5       ]\n",
      " [0.41666667 0.2       ]\n",
      " [0.58333333 0.7       ]\n",
      " [0.         0.5       ]\n",
      " [0.         0.1       ]\n",
      " [0.41666667 0.6       ]\n",
      " [1.         0.6       ]\n",
      " [0.16666667 0.1       ]\n",
      " [0.16666667 0.2       ]\n",
      " [1.         0.5       ]\n",
      " [0.83333333 0.8       ]]\n",
      "****\n",
      "9     L\n",
      "17    L\n",
      "13    L\n",
      "5     M\n",
      "11    L\n",
      "2     M\n",
      "1     M\n",
      "8     L\n",
      "16    L\n",
      "3     M\n",
      "4     M\n",
      "15    L\n",
      "14    L\n",
      "Name: t-shirt size, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, stratify=y)\n",
    "# random_state=0 for reproducible resultbb\n",
    "# stratify=y to force the same distribution of class labels in your training and testing set\n",
    "\n",
    "print(X_train)\n",
    "print(\"****\")\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83333333 0.4       ]\n",
      " [0.41666667 0.3       ]\n",
      " [0.16666667 0.6       ]\n",
      " [0.         0.        ]\n",
      " [0.58333333 0.4       ]]\n",
      "12    L\n",
      "6     M\n",
      "7     L\n",
      "0     M\n",
      "10    L\n",
      "Name: t-shirt size, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "['L' 'M' 'M' 'M' 'L']\n",
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn_clf.fit(X_train, y_train)\n",
    "acc = knn_clf.score(X_test, y_test)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "# Or\n",
    "\n",
    "y_predicted = knn_clf.predict(X_test)\n",
    "print(y_predicted)\n",
    "acc = accuracy_score(y_test, y_predicted)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=0)\n",
    "tree_clf.fit(X_train, y_train) # to train\n",
    "acc = tree_clf.score(X_test, y_test)\n",
    "print(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k Fold Cross Validation\n",
    "* With cross validation, every instance is in the test set exactly one time\n",
    "* Basic algorithm: divide the dataset into \"folds\"\n",
    "    * For each fold:\n",
    "        * Test on the fold\n",
    "        * Train on the remaining folds (folds - fold)\n",
    "* Accuracy is the total correctly predicted over all the folds divided by the total number of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "[0.75       0.5        1.         1.         0.66666667] 0.7833333333333333\n",
      "0.7777777777777778\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "[0.5        0.5        1.         1.         0.66666667] 0.7333333333333333\n",
      "0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "# Do 5 fold cross validation for the kNN and decision tree classifiers\n",
    "for clf in [knn_clf, tree_clf]:\n",
    "    print(type(clf))\n",
    "    accuracies = cross_val_score(clf, X, y)\n",
    "    print(accuracies, np.mean(accuracies))\n",
    "    # The preferred way to calculate accuracy\n",
    "    y_predicted = cross_val_predict(clf, X, y)\n",
    "    acc = accuracy_score(y, y_predicted)\n",
    "    print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ccfa51b6a2c575f9ec4b5f633399d96d9a08ae2d3de4a2b338c15ea2dbb5975"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
